{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/serengil/retinaface.git\n",
      "  Cloning https://github.com/serengil/retinaface.git to /tmp/pip-req-build-4j59k0nq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/serengil/retinaface.git /tmp/pip-req-build-4j59k0nq\n",
      "  Resolved https://github.com/serengil/retinaface.git to commit 3ddbbd2e6f3b0e49b51b9ba76a7ad03af4486c5f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from retina-face==0.0.15) (1.23.4)\n",
      "Requirement already satisfied: gdown>=3.10.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from retina-face==0.0.15) (4.7.1)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from retina-face==0.0.15) (9.2.0)\n",
      "Requirement already satisfied: opencv-python>=3.4.4 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from retina-face==0.0.15) (4.9.0.80)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from retina-face==0.0.15) (2.8.4)\n",
      "Requirement already satisfied: filelock in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from gdown>=3.10.1->retina-face==0.0.15) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from gdown>=3.10.1->retina-face==0.0.15) (2.28.1)\n",
      "Requirement already satisfied: six in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from gdown>=3.10.1->retina-face==0.0.15) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from gdown>=3.10.1->retina-face==0.0.15) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from gdown>=3.10.1->retina-face==0.0.15) (4.11.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (14.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (69.0.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (0.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorflow>=1.9.0->retina-face==0.0.15) (1.50.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face==0.0.15) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (3.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from beautifulsoup4->gdown>=3.10.1->retina-face==0.0.15) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.15) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.15) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.15) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.15) (2022.9.24)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.15) (1.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (7.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (3.9.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face==0.0.15) (3.2.2)\n",
      "Building wheels for collected packages: retina-face\n",
      "  Building wheel for retina-face (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retina-face: filename=retina_face-0.0.15-py3-none-any.whl size=24236 sha256=76c4d463637f7f72065e11d99a0e00988adefdd5ea4fd3c669f2f10550b5293f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-76z0wn0a/wheels/16/27/32/e83a80b48c2100157aff36ae7cbda0160468770403faf90027\n",
      "Successfully built retina-face\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/terry/miniconda3/envs/mlp/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: retina-face\n",
      "  Attempting uninstall: retina-face\n",
      "    Found existing installation: retina-face 0.0.13\n",
      "    Uninstalling retina-face-0.0.13:\n",
      "      Successfully uninstalled retina-face-0.0.13\n",
      "Successfully installed retina-face-0.0.15\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install retina-face deepface\n",
    "%pip install git+https://github.com/serengil/retinaface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function extract_faces in module retinaface.RetinaFace:\n",
      "\n",
      "extract_faces(img_path: Union[str, numpy.ndarray], threshold: float = 0.9, model: Optional[keras.engine.training.Model] = None, align: bool = True, allow_upscaling: bool = True, expand_face_area: int = 0, align_first: bool = False) -> list\n",
      "    Extract detected and aligned faces\n",
      "    Args:\n",
      "        img_path (str or numpy): given image\n",
      "        threshold (float): detection threshold\n",
      "        model (Model): pre-trained model can be passed to the function\n",
      "        align (bool): enable or disable alignment\n",
      "        allow_upscaling (bool): allowing up-scaling\n",
      "        expand_face_area (int): expand detected facial area with a percentage\n",
      "        align_first (bool): set this True to align first and detect second\n",
      "            this can be applied only if input image has just one face\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "help(RetinaFace.extract_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/남자/BTS RM/03.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/09.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/10.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/108.png\n",
      "24-02-13 09:03:42 - ⚠️ Even though align_first is set to True, there are 3 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/108.png has more than 1 face.\n",
      "images/남자/BTS RM/112.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/115.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/116.png\n",
      "24-02-13 09:03:56 - ⚠️ Even though align_first is set to True, there are 2 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/116.png has more than 1 face.\n",
      "images/남자/BTS RM/119.png\n",
      "24-02-13 09:04:00 - ⚠️ Even though align_first is set to True, there are 4 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/119.png has more than 1 face.\n",
      "images/남자/BTS RM/120.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/122.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/126.png\n",
      "24-02-13 09:04:13 - ⚠️ Even though align_first is set to True, there are 2 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/126.png has more than 1 face.\n",
      "images/남자/BTS RM/127.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/128.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/136.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/137.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/139.png\n",
      "24-02-13 09:04:34 - ⚠️ Even though align_first is set to True, there are 2 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/139.png has more than 1 face.\n",
      "images/남자/BTS RM/14.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/141.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/142.png\n",
      "24-02-13 09:04:48 - ⚠️ Even though align_first is set to True, there are 4 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/142.png has more than 1 face.\n",
      "images/남자/BTS RM/144.png\n",
      "24-02-13 09:04:51 - ⚠️ Even though align_first is set to True, there are 3 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/144.png has more than 1 face.\n",
      "images/남자/BTS RM/145.png\n",
      "24-02-13 09:04:55 - ⚠️ Even though align_first is set to True, there are 14 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/145.png has more than 1 face.\n",
      "images/남자/BTS RM/146.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/151.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/154.png\n",
      "24-02-13 09:05:09 - ⚠️ Even though align_first is set to True, there are 7 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/154.png has more than 1 face.\n",
      "images/남자/BTS RM/159.png\n",
      "24-02-13 09:05:13 - ⚠️ Even though align_first is set to True, there are 2 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/159.png has more than 1 face.\n",
      "images/남자/BTS RM/166.png\n",
      "24-02-13 09:05:19 - ⚠️ Even though align_first is set to True, there are 8 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/166.png has more than 1 face.\n",
      "images/남자/BTS RM/181.png\n",
      "24-02-13 09:05:22 - ⚠️ Even though align_first is set to True, there are 2 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/181.png has more than 1 face.\n",
      "images/남자/BTS RM/186.png\n",
      "24-02-13 09:05:27 - ⚠️ Even though align_first is set to True, there are 2 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/186.png has more than 1 face.\n",
      "images/남자/BTS RM/187.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/188.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/189.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/19.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/193.png\n",
      "24-02-13 09:05:50 - ⚠️ Even though align_first is set to True, there are 7 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/193.png has more than 1 face.\n",
      "images/남자/BTS RM/196.png\n",
      "24-02-13 09:05:54 - ⚠️ Even though align_first is set to True, there are 4 faces in input image.Align first functionality can be applied only if there is single face in the input\n",
      "images/남자/BTS RM/196.png has more than 1 face.\n",
      "images/남자/BTS RM/199.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/217.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/218.png\n",
      "0 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/22.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/224.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/229.png\n",
      "resizing..\n",
      "1 faces detected and saved to faces/남자/BTS RM\n",
      "images/남자/BTS RM/234.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/terry/code/celebme/celebme_model_202401/Cut images batch.ipynb 셀 3\u001b[0m in \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# input_image_path = '01.png'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m output_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_faces, gender, name)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m face_idx \u001b[39m=\u001b[39m detect_and_save_faces(path_img_file, output_folder, face_idx)\n",
      "\u001b[1;32m/home/terry/code/celebme/celebme_model_202401/Cut images batch.ipynb 셀 3\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(input_image_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Detect faces using the SSD model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     detected_faces \u001b[39m=\u001b[39m RetinaFace\u001b[39m.\u001b[39;49mextract_faces(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         input_image_path,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         threshold\u001b[39m=\u001b[39;49m\u001b[39m0.97\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m         align\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m         align_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m         allow_upscaling\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         expand_face_area\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(detected_faces) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btkorg.duckdns.org/home/terry/code/celebme/celebme_model_202401/Cut%20images%20batch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00minput_image_path\u001b[39m}\u001b[39;00m\u001b[39m has more than 1 face.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/retinaface/RetinaFace.py:237\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img_path, threshold, model, align, allow_upscaling, expand_face_area, align_first)\u001b[0m\n\u001b[1;32m    233\u001b[0m img \u001b[39m=\u001b[39m preprocess\u001b[39m.\u001b[39mget_image(img_path)\n\u001b[1;32m    235\u001b[0m \u001b[39m# ---------------------------\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m obj \u001b[39m=\u001b[39m detect_faces(\n\u001b[1;32m    238\u001b[0m     img_path\u001b[39m=\u001b[39;49mimg, threshold\u001b[39m=\u001b[39;49mthreshold, model\u001b[39m=\u001b[39;49mmodel, allow_upscaling\u001b[39m=\u001b[39;49mallow_upscaling\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m align_first \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    242\u001b[0m     logger\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEven though align_first is set to True, there are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m faces in input image.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAlign first functionality can be applied only if there is single face in the input\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/retinaface/RetinaFace.py:115\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(img_path, threshold, model, allow_upscaling)\u001b[0m\n\u001b[1;32m    113\u001b[0m landmarks_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    114\u001b[0m im_tensor, im_info, im_scale \u001b[39m=\u001b[39m preprocess\u001b[39m.\u001b[39mpreprocess_image(img, allow_upscaling)\n\u001b[0;32m--> 115\u001b[0m net_out \u001b[39m=\u001b[39m model(im_tensor)\n\u001b[1;32m    116\u001b[0m net_out \u001b[39m=\u001b[39m [elt\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m net_out]\n\u001b[1;32m    117\u001b[0m sym_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "model = RetinaFace.build_model()\n",
    "\n",
    "\n",
    "def detect_and_save_faces(input_image_path, output_folder, face_idx):\n",
    "    # Load the input image\n",
    "    image = cv2.imread(input_image_path)\n",
    "\n",
    "    try:\n",
    "        # Detect faces using the SSD model\n",
    "        detected_faces = RetinaFace.extract_faces(\n",
    "            input_image_path,\n",
    "            threshold=0.97,\n",
    "            model=model,\n",
    "            align=True,\n",
    "            align_first=True,\n",
    "            allow_upscaling=True,\n",
    "            expand_face_area=10,\n",
    "        )\n",
    "        \n",
    "        if len(detected_faces) > 1:\n",
    "            print(f'{input_image_path} has more than 1 face.')\n",
    "            return face_idx\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Loop through each detected face and save it as a 300x300 PNG file\n",
    "        for i, face_info in enumerate(detected_faces):\n",
    "            face = face_info\n",
    "            # print(face)\n",
    "\n",
    "            print(\"resizing..\")\n",
    "            maxwidth, maxheight = 300, 300\n",
    "            f1 = maxwidth / face.shape[1]\n",
    "            f2 = maxheight / face.shape[0]\n",
    "            f = min(f1, f2)\n",
    "            dim = (int(face.shape[1] * f), int(face.shape[0] * f))\n",
    "            face_resized = cv2.resize(face, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Create a black image with the target size\n",
    "            padded_image = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "            padding_rows = (300 - dim[1]) // 2\n",
    "            padding_cols = (300 - dim[0]) // 2\n",
    "\n",
    "            # Add the resized image to the padded image, with padding on the left and right sides\n",
    "            padded_image[padding_rows : padding_rows + dim[1], padding_cols : padding_cols + dim[0]] = face_rgb\n",
    "\n",
    "            face_idx += 1\n",
    "            # Save the face as a PNG file in the output folder\n",
    "            output_path = os.path.join(output_folder, f\"face_{face_idx}.png\")\n",
    "            cv2.imwrite(output_path, padded_image)\n",
    "\n",
    "        print(f\"{len(detected_faces)} faces detected and saved to {output_folder}\")\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    return face_idx\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "path_img = \"images\"\n",
    "path_faces = \"faces\"\n",
    "\n",
    "# # test\n",
    "# input_image_path = '01.png'\n",
    "# output_folder = 'output/'\n",
    "# detect_and_save_faces(input_image_path, output_folder, 0)\n",
    "\n",
    "for gender in sorted(os.listdir(path_img)):\n",
    "    path_gender = os.path.join(path_img, gender)\n",
    "    for name in sorted(os.listdir(path_gender)):\n",
    "        if os.path.exists(os.path.join(path_faces, gender, name)):\n",
    "            continue\n",
    "        \n",
    "        path_name = os.path.join(path_img, gender, name)\n",
    "        face_idx = 0\n",
    "        for path_file in sorted(os.listdir(path_name)):\n",
    "            path_img_file = os.path.join(path_name, path_file)\n",
    "            if os.path.getsize(path_img_file) < 200000:\n",
    "                continue\n",
    "            print(path_img_file)\n",
    "            # input_image_path = '01.png'\n",
    "            output_folder = os.path.join(path_faces, gender, name)\n",
    "            face_idx = detect_and_save_faces(path_img_file, output_folder, face_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
